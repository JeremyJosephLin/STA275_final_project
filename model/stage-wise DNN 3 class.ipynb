{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05b821f5",
   "metadata": {},
   "source": [
    "# Trying to do fusion using a deep learning method \n",
    "\n",
    "#### importing data + choosing imputing method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbbf6a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter, defaultdict\n",
    "from importlib import reload\n",
    "\n",
    "import torch\n",
    "from torch import optim, nn\n",
    "import torch.utils.data as Data\n",
    "from torch.nn import functional as F\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "import pydot\n",
    "import tensorflow as tf \n",
    "\n",
    "# Import necessary modules\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "\n",
    "# Keras specific\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edbcc826",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_torch(seed=0):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)#as reproducibility docs\n",
    "    torch.manual_seed(seed)# as reproducibility docs\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False# as reproducibility docs\n",
    "    torch.backends.cudnn.deterministic = True# as reproducibility docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40ecf33c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44740, 89) (2873, 161) (2180, 7)\n"
     ]
    }
   ],
   "source": [
    "def load_data(impute_method = 'RF'):\n",
    "    uds = pd.read_csv(\"../data/data_imputed/{}/uds.csv\".format(impute_method))\n",
    "    uds['datetime'] = pd.to_datetime(uds['datetime'])\n",
    "    uds = uds.dropna(subset=['EDUC'])\n",
    "    \n",
    "    mri = pd.read_csv(\"../data/data_imputed/{}/mri.csv\".format(impute_method))\n",
    "    mri['datetime'] = pd.to_datetime(mri['datetime'])\n",
    "    \n",
    "    csf = pd.read_csv(\"../data/data_imputed/{}/csf.csv\".format(impute_method))\n",
    "    return uds, mri, csf\n",
    "\n",
    "uds_dict = pd.read_csv(\"../data/data_dictionary/uds_feature_dictionary_cleaned.csv\")\n",
    "mri_dict = pd.read_csv(\"../data/data_dictionary/mri_feature_dictionary_cleaned.csv\") \n",
    "\n",
    "uds_drop_columns = ['NACCID', 'NACCADC', 'NACCVNUM', 'datetime', 'NACCUDSD', 'NACCALZP', 'NACCAD3', 'NACCAD5']\n",
    "mri_drop_columns = ['NACCID', 'NACCVNUM', 'datetime', 'datetime_UDS', 'timediff', 'within-a-year']\n",
    "csf_drop_columns = ['NACCID', 'CSFABMD', 'CSFTTMD', 'CSFPTMD']\n",
    "\n",
    "uds, mri, csf = load_data()\n",
    "print(uds.shape, mri.shape, csf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a781409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NACCID</th>\n",
       "      <th>NACCAD3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NACC020208</td>\n",
       "      <td>MCI-AD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NACC107305</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NACC151065</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NACC187327</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NACC188799</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45095</th>\n",
       "      <td>NACC993286</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45096</th>\n",
       "      <td>NACC994463</td>\n",
       "      <td>Dementia-AD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45097</th>\n",
       "      <td>NACC995870</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45098</th>\n",
       "      <td>NACC998475</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45099</th>\n",
       "      <td>NACC999391</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44740 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           NACCID      NACCAD3\n",
       "0      NACC020208       MCI-AD\n",
       "1      NACC107305      Healthy\n",
       "2      NACC151065          NaN\n",
       "3      NACC187327      Healthy\n",
       "4      NACC188799          NaN\n",
       "...           ...          ...\n",
       "45095  NACC993286          NaN\n",
       "45096  NACC994463  Dementia-AD\n",
       "45097  NACC995870      Healthy\n",
       "45098  NACC998475          NaN\n",
       "45099  NACC999391          NaN\n",
       "\n",
       "[44740 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uds[['NACCID','NACCAD3']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf03df1e",
   "metadata": {},
   "source": [
    "#### add classifying variable (UDS/ALZP) to the MRI and CSF data sets\n",
    "\n",
    "Need to add the class for each of the people in each data set so that we can do the initial step of the deep neural net. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fdef745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NACCID</th>\n",
       "      <th>NACCVNUM</th>\n",
       "      <th>datetime</th>\n",
       "      <th>datetime_UDS</th>\n",
       "      <th>timediff</th>\n",
       "      <th>within-a-year</th>\n",
       "      <th>NACCICV</th>\n",
       "      <th>NACCBRNV</th>\n",
       "      <th>NACCWMVL</th>\n",
       "      <th>CSFVOL</th>\n",
       "      <th>...</th>\n",
       "      <th>RSUPFRM</th>\n",
       "      <th>RSUPPAR</th>\n",
       "      <th>RSUPPARM</th>\n",
       "      <th>RSUPTEM</th>\n",
       "      <th>RSUPTEMM</th>\n",
       "      <th>RSUPMAR</th>\n",
       "      <th>RSUPMARM</th>\n",
       "      <th>RTRTEM</th>\n",
       "      <th>RTRTEMM</th>\n",
       "      <th>NACCAD3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NACC914950</td>\n",
       "      <td>11</td>\n",
       "      <td>2017-03-02</td>\n",
       "      <td>2006-10-31</td>\n",
       "      <td>3775</td>\n",
       "      <td>False</td>\n",
       "      <td>1535.13000</td>\n",
       "      <td>1081.63</td>\n",
       "      <td>504.80000</td>\n",
       "      <td>407.37</td>\n",
       "      <td>...</td>\n",
       "      <td>2.11</td>\n",
       "      <td>10.53</td>\n",
       "      <td>1.61</td>\n",
       "      <td>15.71</td>\n",
       "      <td>2.02</td>\n",
       "      <td>7.24</td>\n",
       "      <td>1.89</td>\n",
       "      <td>0.720</td>\n",
       "      <td>1.2100</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NACC388999</td>\n",
       "      <td>11</td>\n",
       "      <td>2016-06-24</td>\n",
       "      <td>2006-02-21</td>\n",
       "      <td>3776</td>\n",
       "      <td>False</td>\n",
       "      <td>1314.57000</td>\n",
       "      <td>1001.09</td>\n",
       "      <td>437.70000</td>\n",
       "      <td>312.44</td>\n",
       "      <td>...</td>\n",
       "      <td>2.70</td>\n",
       "      <td>10.17</td>\n",
       "      <td>2.00</td>\n",
       "      <td>13.07</td>\n",
       "      <td>2.17</td>\n",
       "      <td>8.92</td>\n",
       "      <td>2.09</td>\n",
       "      <td>0.630</td>\n",
       "      <td>1.6100</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NACC550785</td>\n",
       "      <td>10</td>\n",
       "      <td>2015-06-02</td>\n",
       "      <td>2006-03-28</td>\n",
       "      <td>3353</td>\n",
       "      <td>False</td>\n",
       "      <td>1571.92000</td>\n",
       "      <td>1210.39</td>\n",
       "      <td>516.57000</td>\n",
       "      <td>358.48</td>\n",
       "      <td>...</td>\n",
       "      <td>2.47</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.64</td>\n",
       "      <td>13.90</td>\n",
       "      <td>2.01</td>\n",
       "      <td>10.37</td>\n",
       "      <td>1.89</td>\n",
       "      <td>0.750</td>\n",
       "      <td>1.9000</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NACC321645</td>\n",
       "      <td>9</td>\n",
       "      <td>2015-12-03</td>\n",
       "      <td>2006-01-03</td>\n",
       "      <td>3621</td>\n",
       "      <td>False</td>\n",
       "      <td>1417.97000</td>\n",
       "      <td>1043.73</td>\n",
       "      <td>431.46000</td>\n",
       "      <td>372.57</td>\n",
       "      <td>...</td>\n",
       "      <td>2.33</td>\n",
       "      <td>12.02</td>\n",
       "      <td>1.68</td>\n",
       "      <td>14.07</td>\n",
       "      <td>2.06</td>\n",
       "      <td>8.38</td>\n",
       "      <td>1.97</td>\n",
       "      <td>0.980</td>\n",
       "      <td>1.5800</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NACC129206</td>\n",
       "      <td>10</td>\n",
       "      <td>2015-12-09</td>\n",
       "      <td>2006-04-18</td>\n",
       "      <td>3522</td>\n",
       "      <td>False</td>\n",
       "      <td>1553.60000</td>\n",
       "      <td>1086.93</td>\n",
       "      <td>425.40000</td>\n",
       "      <td>464.06</td>\n",
       "      <td>...</td>\n",
       "      <td>2.47</td>\n",
       "      <td>13.44</td>\n",
       "      <td>1.62</td>\n",
       "      <td>16.53</td>\n",
       "      <td>2.32</td>\n",
       "      <td>10.38</td>\n",
       "      <td>2.02</td>\n",
       "      <td>1.534</td>\n",
       "      <td>2.2308</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2855</th>\n",
       "      <td>NACC159647</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-05-11</td>\n",
       "      <td>2016-02-18</td>\n",
       "      <td>83</td>\n",
       "      <td>True</td>\n",
       "      <td>1336.42000</td>\n",
       "      <td>981.58</td>\n",
       "      <td>444.05000</td>\n",
       "      <td>351.36</td>\n",
       "      <td>...</td>\n",
       "      <td>2.26</td>\n",
       "      <td>8.84</td>\n",
       "      <td>1.53</td>\n",
       "      <td>11.88</td>\n",
       "      <td>2.24</td>\n",
       "      <td>8.98</td>\n",
       "      <td>1.86</td>\n",
       "      <td>0.790</td>\n",
       "      <td>1.5600</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2856</th>\n",
       "      <td>NACC732291</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-06-13</td>\n",
       "      <td>2016-04-05</td>\n",
       "      <td>69</td>\n",
       "      <td>True</td>\n",
       "      <td>1339.20000</td>\n",
       "      <td>959.04</td>\n",
       "      <td>419.74000</td>\n",
       "      <td>378.69</td>\n",
       "      <td>...</td>\n",
       "      <td>2.65</td>\n",
       "      <td>9.04</td>\n",
       "      <td>1.52</td>\n",
       "      <td>11.57</td>\n",
       "      <td>1.95</td>\n",
       "      <td>6.99</td>\n",
       "      <td>2.07</td>\n",
       "      <td>0.910</td>\n",
       "      <td>1.7000</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2857</th>\n",
       "      <td>NACC650247</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-05-06</td>\n",
       "      <td>2016-04-07</td>\n",
       "      <td>29</td>\n",
       "      <td>True</td>\n",
       "      <td>1343.77000</td>\n",
       "      <td>934.67</td>\n",
       "      <td>394.78000</td>\n",
       "      <td>398.83</td>\n",
       "      <td>...</td>\n",
       "      <td>2.39</td>\n",
       "      <td>8.37</td>\n",
       "      <td>1.33</td>\n",
       "      <td>12.00</td>\n",
       "      <td>2.36</td>\n",
       "      <td>6.78</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0.710</td>\n",
       "      <td>1.5700</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2858</th>\n",
       "      <td>NACC050273</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-05-24</td>\n",
       "      <td>2016-04-12</td>\n",
       "      <td>42</td>\n",
       "      <td>True</td>\n",
       "      <td>1437.06000</td>\n",
       "      <td>1058.00</td>\n",
       "      <td>435.41000</td>\n",
       "      <td>376.57</td>\n",
       "      <td>...</td>\n",
       "      <td>2.36</td>\n",
       "      <td>7.40</td>\n",
       "      <td>1.30</td>\n",
       "      <td>15.12</td>\n",
       "      <td>2.33</td>\n",
       "      <td>9.02</td>\n",
       "      <td>1.84</td>\n",
       "      <td>0.850</td>\n",
       "      <td>1.2500</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2859</th>\n",
       "      <td>NACC635044</td>\n",
       "      <td>5</td>\n",
       "      <td>2014-04-18</td>\n",
       "      <td>2008-01-15</td>\n",
       "      <td>2285</td>\n",
       "      <td>False</td>\n",
       "      <td>1343.14066</td>\n",
       "      <td>1080.86</td>\n",
       "      <td>430.57896</td>\n",
       "      <td>320.46</td>\n",
       "      <td>...</td>\n",
       "      <td>2.51</td>\n",
       "      <td>10.89</td>\n",
       "      <td>1.78</td>\n",
       "      <td>14.53</td>\n",
       "      <td>2.25</td>\n",
       "      <td>10.60</td>\n",
       "      <td>2.03</td>\n",
       "      <td>0.860</td>\n",
       "      <td>1.9000</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2860 rows × 162 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          NACCID  NACCVNUM   datetime datetime_UDS  timediff  within-a-year  \\\n",
       "0     NACC914950        11 2017-03-02   2006-10-31      3775          False   \n",
       "1     NACC388999        11 2016-06-24   2006-02-21      3776          False   \n",
       "2     NACC550785        10 2015-06-02   2006-03-28      3353          False   \n",
       "3     NACC321645         9 2015-12-03   2006-01-03      3621          False   \n",
       "4     NACC129206        10 2015-12-09   2006-04-18      3522          False   \n",
       "...          ...       ...        ...          ...       ...            ...   \n",
       "2855  NACC159647         1 2016-05-11   2016-02-18        83           True   \n",
       "2856  NACC732291         1 2016-06-13   2016-04-05        69           True   \n",
       "2857  NACC650247         1 2016-05-06   2016-04-07        29           True   \n",
       "2858  NACC050273         1 2016-05-24   2016-04-12        42           True   \n",
       "2859  NACC635044         5 2014-04-18   2008-01-15      2285          False   \n",
       "\n",
       "         NACCICV  NACCBRNV   NACCWMVL  CSFVOL  ...  RSUPFRM  RSUPPAR  \\\n",
       "0     1535.13000   1081.63  504.80000  407.37  ...     2.11    10.53   \n",
       "1     1314.57000   1001.09  437.70000  312.44  ...     2.70    10.17   \n",
       "2     1571.92000   1210.39  516.57000  358.48  ...     2.47    13.20   \n",
       "3     1417.97000   1043.73  431.46000  372.57  ...     2.33    12.02   \n",
       "4     1553.60000   1086.93  425.40000  464.06  ...     2.47    13.44   \n",
       "...          ...       ...        ...     ...  ...      ...      ...   \n",
       "2855  1336.42000    981.58  444.05000  351.36  ...     2.26     8.84   \n",
       "2856  1339.20000    959.04  419.74000  378.69  ...     2.65     9.04   \n",
       "2857  1343.77000    934.67  394.78000  398.83  ...     2.39     8.37   \n",
       "2858  1437.06000   1058.00  435.41000  376.57  ...     2.36     7.40   \n",
       "2859  1343.14066   1080.86  430.57896  320.46  ...     2.51    10.89   \n",
       "\n",
       "      RSUPPARM  RSUPTEM  RSUPTEMM  RSUPMAR  RSUPMARM  RTRTEM  RTRTEMM  NACCAD3  \n",
       "0         1.61    15.71      2.02     7.24      1.89   0.720   1.2100  Healthy  \n",
       "1         2.00    13.07      2.17     8.92      2.09   0.630   1.6100      NaN  \n",
       "2         1.64    13.90      2.01    10.37      1.89   0.750   1.9000  Healthy  \n",
       "3         1.68    14.07      2.06     8.38      1.97   0.980   1.5800      NaN  \n",
       "4         1.62    16.53      2.32    10.38      2.02   1.534   2.2308  Healthy  \n",
       "...        ...      ...       ...      ...       ...     ...      ...      ...  \n",
       "2855      1.53    11.88      2.24     8.98      1.86   0.790   1.5600  Healthy  \n",
       "2856      1.52    11.57      1.95     6.99      2.07   0.910   1.7000  Healthy  \n",
       "2857      1.33    12.00      2.36     6.78      1.70   0.710   1.5700  Healthy  \n",
       "2858      1.30    15.12      2.33     9.02      1.84   0.850   1.2500  Healthy  \n",
       "2859      1.78    14.53      2.25    10.60      2.03   0.860   1.9000  Healthy  \n",
       "\n",
       "[2860 rows x 162 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#uds_sub_mri = uds[uds['NACCID'].isin(mri['NACCID'])]\n",
    "#uds_sub_mri\n",
    "mri = pd.merge(mri, uds[[\"NACCID\",'NACCAD3']], on=\"NACCID\", how=\"inner\")\n",
    "mri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18b6d142",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Healthy        1563\n",
       "Dementia-AD     469\n",
       "MCI-AD          306\n",
       "Name: NACCAD3, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mri['NACCAD3'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a3822e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Healthy        1074\n",
       "Dementia-AD     600\n",
       "MCI-AD          144\n",
       "Name: NACCAD3, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csf = pd.merge(csf, uds[[\"NACCID\",'NACCAD3']], on=\"NACCID\", how=\"inner\")\n",
    "csf['NACCAD3'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec1e6d4",
   "metadata": {},
   "source": [
    "## first layer - individual DNNs \n",
    "\n",
    "### UDS data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a09bacc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34025, 90)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#recode the response variable to numeric\n",
    "uds['NACCAD3_num'] = uds['NACCAD3'].map({'Healthy':0, 'MCI-AD':1,  'Dementia-AD':2})\n",
    "\n",
    "#get rid of rows where classification has not been possible \n",
    "uds = uds.dropna(subset=['NACCAD3'])\n",
    "\n",
    "#designate which column we are trying to predict\n",
    "target_column = ['NACCAD3_num'] \n",
    "\n",
    "predictors = list(set(list(uds.columns))-set(target_column)- set(uds_drop_columns)-set(['NACCAD3']))\n",
    "uds[predictors] = uds[predictors]/uds[predictors].max()\n",
    "uds.describe()\n",
    "uds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "584779f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['NACC020208'],\n",
       "       ['NACC107305'],\n",
       "       ['NACC187327'],\n",
       "       ...,\n",
       "       ['NACC993141'],\n",
       "       ['NACC994463'],\n",
       "       ['NACC995870']], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predictors\n",
    "uds[['NACCID']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "118fcf92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32323, 82)\n",
      "(32323, 3)\n"
     ]
    }
   ],
   "source": [
    "X_uds = np.concatenate((uds[['NACCID']].values,uds[predictors].values), axis = 1 )\n",
    "y_uds = uds[target_column].values\n",
    "\n",
    "#change it so that we have an ecoded variable for our classification\n",
    "# one hot encode outputs \n",
    "y_uds = keras.utils.to_categorical(y_uds, num_classes=3)\n",
    "\n",
    "X_uds_train, X_uds_test, y_uds_train, y_uds_test = train_test_split(X_uds, y_uds, test_size=0.05,  random_state=20)\n",
    "print(X_uds_train.shape); print(y_uds_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ddf61dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#want a record of which IDs were used in training and testing so can keep the right ones when \n",
    "#we merge with output from other models \n",
    "#split X_train into a vector of everything but IDs and the IDs \n",
    "X_uds_train_ID = X_uds_train[:,0]\n",
    "X_uds_train = np.delete(X_uds_train,0, 1 )\n",
    "X_uds_train = X_uds_train.astype(float)\n",
    "X_uds_test_ID = X_uds_test[:,0]\n",
    "X_uds_test = np.delete(X_uds_test,0, 1 )\n",
    "X_uds_test = X_uds_test.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ddfb242",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "count_classes = y_uds_test.shape[1]\n",
    "print(count_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fbfe2341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34025, 4)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#also need training data with the ID in so that we can merge it later on \n",
    "y_uds_ID = np.column_stack((X_uds[:,0], y_uds))\n",
    "y_uds_ID.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d215bf",
   "metadata": {},
   "source": [
    "### UDS Model set up / compile / run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ca9f931b",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_ma = tfa.metrics.F1Score(num_classes=3, average='macro')\n",
    "f1_mi = tfa.metrics.FBetaScore(num_classes=3, average='micro') #this seems to be the same as \n",
    "#the accuracy so i think somehting is wrong "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b3c18b79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32323, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_uds_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f71047fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_uds = Sequential()\n",
    "model_uds.add(Dense(500, activation='relu', input_dim=X_uds_train.shape[1]))\n",
    "model_uds.add(Dense(250, activation='relu'))\n",
    "model_uds.add(Dense(50, activation='relu'))\n",
    "model_uds.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model_uds.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy', f1_ma])\n",
    "#f1_score is macro F1\n",
    "#fbeta_score is micro F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "31bee034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1011/1011 [==============================] - 9s 6ms/step - loss: 0.2624 - accuracy: 0.8948 - f1_score: 0.8229\n",
      "Epoch 2/20\n",
      "1011/1011 [==============================] - 6s 6ms/step - loss: 0.2406 - accuracy: 0.9040 - f1_score: 0.8410\n",
      "Epoch 3/20\n",
      "1011/1011 [==============================] - 6s 6ms/step - loss: 0.2377 - accuracy: 0.9038 - f1_score: 0.8403\n",
      "Epoch 4/20\n",
      "1011/1011 [==============================] - 6s 6ms/step - loss: 0.2327 - accuracy: 0.9073 - f1_score: 0.8458\n",
      "Epoch 5/20\n",
      "1011/1011 [==============================] - 6s 6ms/step - loss: 0.2299 - accuracy: 0.9087 - f1_score: 0.8477\n",
      "Epoch 6/20\n",
      "1011/1011 [==============================] - 6s 6ms/step - loss: 0.2249 - accuracy: 0.9099 - f1_score: 0.8500\n",
      "Epoch 7/20\n",
      "1011/1011 [==============================] - 6s 6ms/step - loss: 0.2224 - accuracy: 0.9122 - f1_score: 0.8544\n",
      "Epoch 8/20\n",
      "1011/1011 [==============================] - 6s 6ms/step - loss: 0.2185 - accuracy: 0.9129 - f1_score: 0.8563\n",
      "Epoch 9/20\n",
      "1011/1011 [==============================] - 6s 6ms/step - loss: 0.2147 - accuracy: 0.9152 - f1_score: 0.8579\n",
      "Epoch 10/20\n",
      "1011/1011 [==============================] - 6s 6ms/step - loss: 0.2112 - accuracy: 0.9153 - f1_score: 0.8596\n",
      "Epoch 11/20\n",
      "1011/1011 [==============================] - 5s 5ms/step - loss: 0.2061 - accuracy: 0.9158 - f1_score: 0.8598\n",
      "Epoch 12/20\n",
      "1011/1011 [==============================] - 5s 5ms/step - loss: 0.2004 - accuracy: 0.9197 - f1_score: 0.8662\n",
      "Epoch 13/20\n",
      "1011/1011 [==============================] - 5s 5ms/step - loss: 0.1955 - accuracy: 0.9226 - f1_score: 0.8712\n",
      "Epoch 14/20\n",
      "1011/1011 [==============================] - 5s 5ms/step - loss: 0.1913 - accuracy: 0.9231 - f1_score: 0.8712\n",
      "Epoch 15/20\n",
      "1011/1011 [==============================] - 6s 5ms/step - loss: 0.1858 - accuracy: 0.9249 - f1_score: 0.8750\n",
      "Epoch 16/20\n",
      "1011/1011 [==============================] - 6s 5ms/step - loss: 0.1816 - accuracy: 0.9281 - f1_score: 0.8803\n",
      "Epoch 17/20\n",
      "1011/1011 [==============================] - 6s 5ms/step - loss: 0.1737 - accuracy: 0.9295 - f1_score: 0.8827\n",
      "Epoch 18/20\n",
      "1011/1011 [==============================] - 6s 6ms/step - loss: 0.1704 - accuracy: 0.9322 - f1_score: 0.8870\n",
      "Epoch 19/20\n",
      "1011/1011 [==============================] - 6s 5ms/step - loss: 0.1629 - accuracy: 0.9352 - f1_score: 0.8916\n",
      "Epoch 20/20\n",
      "1011/1011 [==============================] - 6s 5ms/step - loss: 0.1577 - accuracy: 0.9381 - f1_score: 0.8967\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15700329e80>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_uds.fit(X_uds_train, y_uds_train, epochs=20)\n",
    "#am prettuy sure these results are wrong and the numbers shouldn't be that good ??? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "43d2beeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 0s 3ms/step\n",
      "UDS Accuracy on test data: 0.8942% \n",
      " Error on test data: 0.1058 \n",
      " F1-macro on test: 0.832\n"
     ]
    }
   ],
   "source": [
    "#pred_train_uds= model_uds.predict(X_uds_train)\n",
    "#scores_uds = model_uds.evaluate(X_uds_train, y_uds_train, verbose=0)\n",
    "#print('UDS Accuracy on training data: {}% \\n Error on training data: {}'.format(scores_uds[1], 1 - scores_uds[1]))   \n",
    " \n",
    "pred_test= model_uds.predict(X_uds_test)\n",
    "scores2_uds = model_uds.evaluate(X_uds_test, y_uds_test, verbose=0)\n",
    "print('UDS Accuracy on test data: {}% \\n Error on test data: {} \\n F1-macro on test: {}'.\n",
    "      format(round(scores2_uds[1],4), round(1 - scores2_uds[1],4), round(scores2_uds[2],4)))  \n",
    "\n",
    "#henry was getting f1 scores of like 90 on the test set for whatever he was doing \n",
    "#also does it mean i'm over fitting to the data if the accuracy and the f1 are much higher on the \n",
    "#training set than the testing set???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a33daca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1064/1064 [==============================] - 5s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "#after training the network with our training test and testing set will put the whole data set into the model to give us \n",
    "#our softmax output for the next model \n",
    "uds_all_output = model_uds.predict(np.delete(X_uds,0, 1 ).astype(float))\n",
    "uds_all_output_ID = np.column_stack((X_uds[:,0], uds_all_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "59ab707c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#softmax classification on the full (ish) UDS data set\n",
    "#pred_train_uds_IDs =  np.column_stack((X_uds_train_ID, pred_train_uds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "52ee47b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34025, 4)\n",
      "[['NACC020208' 0.0 1.0 0.0]\n",
      " ['NACC107305' 1.0 0.0 0.0]\n",
      " ['NACC187327' 1.0 0.0 0.0]\n",
      " ...\n",
      " ['NACC993141' 1.0 0.0 0.0]\n",
      " ['NACC994463' 0.0 0.0 1.0]\n",
      " ['NACC995870' 1.0 0.0 0.0]]\n"
     ]
    }
   ],
   "source": [
    "print(uds_all_output_ID.shape) ; print(y_uds_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d76369a",
   "metadata": {},
   "source": [
    "## MRI data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6890e672",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3641: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2338, 163)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#recode the response variable to numeric\n",
    "mri['NACCAD3_num'] = mri['NACCAD3'].map({'Healthy': 0, 'MCI-AD':1 ,'Dementia-AD':2})\n",
    "\n",
    "#get rid of rows where classification has not been possible \n",
    "mri = mri.dropna(subset=['NACCAD3'])\n",
    "\n",
    "#designate which column we are trying to predict\n",
    "target_column = ['NACCAD3_num'] \n",
    "\n",
    "predictors = list(set(list(mri.columns))-set(target_column)- set(mri_drop_columns)-set(['NACCAD3']))\n",
    "mri[predictors] = mri[predictors]/mri[predictors].max()\n",
    "mri.describe()\n",
    "mri.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d929b9a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2221, 156)\n",
      "(117, 156)\n"
     ]
    }
   ],
   "source": [
    "X_mri =np.concatenate((mri[['NACCID']].values,mri[predictors].values), axis = 1 )\n",
    "y_mri = mri[target_column].values\n",
    "\n",
    "#change it so that we have an ecoded variable for our classification\n",
    "# one hot encode outputs \n",
    "y_mri = keras.utils.to_categorical(y_mri)\n",
    "\n",
    "X_mri_train, X_mri_test, y_mri_train, y_mri_test = train_test_split(X_mri, y_mri, test_size=0.05,  random_state=20)\n",
    "print(X_mri_train.shape); print(X_mri_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "707f4fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#want a record of which IDs were used in training and testing so can keep the right ones when \n",
    "#we merge with output from other models \n",
    "#split X_train into a vector of everything but IDs and the IDs \n",
    "X_mri_train_ID = X_mri_train[:,0]\n",
    "X_mri_train = np.delete(X_mri_train,0, 1 )\n",
    "X_mri_train = X_mri_train.astype(float)\n",
    "X_mri_test_ID = X_mri_test[:,0]\n",
    "X_mri_test = np.delete(X_mri_test,0, 1 )\n",
    "X_mri_test = X_mri_test.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "72168ffd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['NACC914950', 1.0, 0.0, 0.0],\n",
       "       ['NACC550785', 1.0, 0.0, 0.0],\n",
       "       ['NACC129206', 1.0, 0.0, 0.0],\n",
       "       ...,\n",
       "       ['NACC650247', 1.0, 0.0, 0.0],\n",
       "       ['NACC050273', 1.0, 0.0, 0.0],\n",
       "       ['NACC635044', 1.0, 0.0, 0.0]], dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#also need training data with the ID in so that we can merge it later on \n",
    "y_mri_ID = np.column_stack((X_mri[:,0], y_mri))\n",
    "y_mri_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f9ea647d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2338, 4)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_mri_ID.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2e1612bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "count_classes = y_mri_test.shape[1]\n",
    "print(count_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6bb2a4",
   "metadata": {},
   "source": [
    "### MRI model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4f9146f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mri = Sequential()\n",
    "model_mri.add(Dense(500, activation='relu', input_dim=X_mri_train.shape[1]))\n",
    "model_mri.add(Dense(300, activation='relu'))\n",
    "model_mri.add(Dense(150, activation='relu'))\n",
    "model_mri.add(Dense(50, activation='relu'))\n",
    "model_mri.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model_mri.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy', f1_ma])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "78aca0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "70/70 [==============================] - 1s 4ms/step - loss: 0.8164 - accuracy: 0.6664 - f1_score: 0.4344\n",
      "Epoch 2/15\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.7234 - accuracy: 0.7186 - f1_score: 0.4476\n",
      "Epoch 3/15\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.6920 - accuracy: 0.7226 - f1_score: 0.4492\n",
      "Epoch 4/15\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.6720 - accuracy: 0.7339 - f1_score: 0.4664\n",
      "Epoch 5/15\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.6409 - accuracy: 0.7515 - f1_score: 0.4867\n",
      "Epoch 6/15\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.6422 - accuracy: 0.7492 - f1_score: 0.4818\n",
      "Epoch 7/15\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.6430 - accuracy: 0.7510 - f1_score: 0.4846\n",
      "Epoch 8/15\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.6188 - accuracy: 0.7668 - f1_score: 0.5040\n",
      "Epoch 9/15\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.6292 - accuracy: 0.7645 - f1_score: 0.4986\n",
      "Epoch 10/15\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.6111 - accuracy: 0.7627 - f1_score: 0.4993\n",
      "Epoch 11/15\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.6159 - accuracy: 0.7636 - f1_score: 0.4989\n",
      "Epoch 12/15\n",
      "70/70 [==============================] - 0s 5ms/step - loss: 0.6104 - accuracy: 0.7668 - f1_score: 0.5071\n",
      "Epoch 13/15\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.6101 - accuracy: 0.7753 - f1_score: 0.5200\n",
      "Epoch 14/15\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.6267 - accuracy: 0.7623 - f1_score: 0.4981\n",
      "Epoch 15/15\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 0.6120 - accuracy: 0.7672 - f1_score: 0.5087\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e6cff71a30>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mri.fit(X_mri_train, y_mri_train, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "24491093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n",
      "MRI Accuracy on test data: 0.7863% \n",
      " Error on test data: 0.2137 \n",
      " F1-macro on test: 0.5198\n"
     ]
    }
   ],
   "source": [
    "#pred_train_mri= model_mri.predict(X_mri_train)\n",
    "#scores_mri = model_mri.evaluate(X_mri_train, y_mri_train, verbose=0)\n",
    "#print('MRI Accuracy on training data: {}% \\n Error on training data: {}'.format(scores_mri[1], 1 - scores_mri[1]))   \n",
    " \n",
    "pred_test_mri= model_mri.predict(X_mri_test)\n",
    "scores2_mri = model_mri.evaluate(X_mri_test, y_mri_test, verbose=0)\n",
    "print('MRI Accuracy on test data: {}% \\n Error on test data: {} \\n F1-macro on test: {}'.format(round(scores2_mri[1],4),\n",
    "                                                                        round(1 - scores2_mri[1],4), round(scores2_mri[2],4)))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f01936de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "#after training the network with our training test and testing set will put the whole data set into the model to give us \n",
    "#our softmax output for the next model \n",
    "mri_all_output = model_mri.predict(np.delete(X_mri,0, 1 ).astype(float))\n",
    "mri_all_output_ID = np.column_stack((X_mri[:,0], mri_all_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2086bcd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2338, 4)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mri_all_output_ID.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfee85e4",
   "metadata": {},
   "source": [
    "### CSF data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0c3e45fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#recode the response variable to numeric\n",
    "csf['NACCAD3_num'] = csf['NACCAD3'].map({'Healthy': 0,  'MCI-AD':1 , 'Dementia-AD':2})\n",
    "\n",
    "#get rid of rows where classification has not been possible \n",
    "csf = csf.dropna(subset=['NACCAD3'])\n",
    "\n",
    "#designate which column we are trying to predict\n",
    "target_column = ['NACCAD3_num'] \n",
    "\n",
    "predictors = list(set(list(csf.columns))-set(target_column)- set(csf_drop_columns)-set(['NACCAD3']))\n",
    "csf[predictors] = csf[predictors]/csf[predictors].max()\n",
    "#csf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "caf51797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1818, 9)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0c086ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1727, 4)\n",
      "(91, 4)\n"
     ]
    }
   ],
   "source": [
    "X_csf =  np.concatenate((csf[['NACCID']].values,csf[predictors].values), axis = 1 )\n",
    "y_csf = csf[target_column].values\n",
    "\n",
    "#change it so that we have an ecoded variable for our classification\n",
    "# one hot encode outputs\n",
    "y_csf = keras.utils.to_categorical(y_csf)\n",
    "\n",
    "X_csf_train, X_csf_test, y_csf_train, y_csf_test = train_test_split(X_csf, y_csf, test_size=0.05,  random_state=20)\n",
    "print(X_csf_train.shape); print(X_csf_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5e934f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "count_classes = y_csf_test.shape[1]\n",
    "print(count_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482507b6",
   "metadata": {},
   "source": [
    "### CSF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "53349d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#want a record of which IDs were used in training and testing so can keep the right ones when \n",
    "#we merge with output from other models \n",
    "#split X_train into a vector of everything but IDs and the IDs \n",
    "X_csf_train_ID = X_csf_train[:,0]\n",
    "X_csf_train = np.delete(X_csf_train,0, 1 )\n",
    "X_csf_train = X_csf_train.astype(float)\n",
    "X_csf_test_ID = X_csf_test[:,0]\n",
    "X_csf_test = np.delete(X_csf_test,0, 1 )\n",
    "X_csf_test = X_csf_test.astype(float)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "64b83ed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['NACC000441', 1.0, 0.0, 0.0],\n",
       "       ['NACC001235', 0.0, 0.0, 1.0],\n",
       "       ['NACC001634', 0.0, 0.0, 1.0],\n",
       "       ...,\n",
       "       ['NACC998175', 0.0, 1.0, 0.0],\n",
       "       ['NACC998324', 1.0, 0.0, 0.0],\n",
       "       ['NACC999002', 0.0, 0.0, 1.0]], dtype=object)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#also need training data with the ID in so that we can merge it later on \n",
    "y_csf_ID = np.column_stack((X_csf[:,0], y_csf))\n",
    "y_csf_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "52ab684d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['NACC000441', 0.13675977653631285, 0.4918893129770992,\n",
       "        0.12825043885313048],\n",
       "       ['NACC001235', 0.15379888268156425, 0.6999045801526718,\n",
       "        0.45985371562317146],\n",
       "       ['NACC001634', 0.10986964618249534, 0.4532442748091603,\n",
       "        0.07899356348741954],\n",
       "       ...,\n",
       "       ['NACC998175', 0.3859217877094972, 0.2538167938931298,\n",
       "        0.2924224692802809],\n",
       "       ['NACC998324', 0.7157045313469894, 0.17032442748091606,\n",
       "        0.15330602691632533],\n",
       "       ['NACC999002', 0.5524518932340161, 0.6665076335877862,\n",
       "        0.564072557050907]], dtype=object)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_csf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6bd64048",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_csf = Sequential()\n",
    "model_csf.add(Dense(150, activation='relu', input_dim=X_csf_train.shape[1]))\n",
    "model_csf.add(Dense(80, activation='relu'))\n",
    "model_csf.add(Dense(50, activation='relu'))\n",
    "model_csf.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model_csf.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy', f1_ma])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "70a162e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.6524 - accuracy: 0.7510 - f1_score: 0.5104\n",
      "Epoch 2/20\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.6560 - accuracy: 0.7487 - f1_score: 0.5092\n",
      "Epoch 3/20\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.6546 - accuracy: 0.7470 - f1_score: 0.5074\n",
      "Epoch 4/20\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6505 - accuracy: 0.7475 - f1_score: 0.5084\n",
      "Epoch 5/20\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.6520 - accuracy: 0.7470 - f1_score: 0.5081\n",
      "Epoch 6/20\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.6538 - accuracy: 0.7528 - f1_score: 0.5110\n",
      "Epoch 7/20\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.6495 - accuracy: 0.7470 - f1_score: 0.5077\n",
      "Epoch 8/20\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.6475 - accuracy: 0.7516 - f1_score: 0.5160\n",
      "Epoch 9/20\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.6483 - accuracy: 0.7487 - f1_score: 0.5089\n",
      "Epoch 10/20\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6477 - accuracy: 0.7499 - f1_score: 0.5093\n",
      "Epoch 11/20\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6489 - accuracy: 0.7510 - f1_score: 0.5105\n",
      "Epoch 12/20\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.6482 - accuracy: 0.7528 - f1_score: 0.5121\n",
      "Epoch 13/20\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.6470 - accuracy: 0.7504 - f1_score: 0.5105\n",
      "Epoch 14/20\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6475 - accuracy: 0.7528 - f1_score: 0.5169\n",
      "Epoch 15/20\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.6435 - accuracy: 0.7528 - f1_score: 0.5213\n",
      "Epoch 16/20\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6509 - accuracy: 0.7585 - f1_score: 0.5164\n",
      "Epoch 17/20\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6445 - accuracy: 0.7510 - f1_score: 0.5108\n",
      "Epoch 18/20\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.6424 - accuracy: 0.7516 - f1_score: 0.5206\n",
      "Epoch 19/20\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.6421 - accuracy: 0.7464 - f1_score: 0.5072\n",
      "Epoch 20/20\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.6423 - accuracy: 0.7481 - f1_score: 0.5227\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e6eeefc5b0>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_csf.fit(X_csf_train, y_csf_train, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4d9ac4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 3ms/step\n",
      "CSF Accuracy on test data: 0.7033% \n",
      " Error on test data: 0.2967 \n",
      " F1-macro on test: 0.4194\n"
     ]
    }
   ],
   "source": [
    "#pred_train_csf= model_csf.predict(X_csf_train)\n",
    "#scores_csf = model_csf.evaluate(X_csf_train, y_csf_train, verbose=0)\n",
    "#print('csf Accuracy on training data: {}% \\n Error on training data: {}'.format(scores_csf[1], 1 - scores_csf[1]))   \n",
    " \n",
    "pred_test_csf= model_csf.predict(X_csf_test)\n",
    "scores2_csf = model_csf.evaluate(X_csf_test, y_csf_test, verbose=0)\n",
    "print('CSF Accuracy on test data: {}% \\n Error on test data: {} \\n F1-macro on test: {}'.format(round(scores2_csf[1],4),\n",
    "                                                                        round(1 - scores2_csf[1],4), round(scores2_csf[2],4))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548a1bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_model(model_uds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b851cb83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "#after training the network with our training test and testing set will put the whole data set into the model to give us \n",
    "#our softmax output for the next model \n",
    "csf_all_output = model_csf.predict(np.delete(X_csf,0, 1 ).astype(float))\n",
    "csf_all_output_ID = np.column_stack((X_csf[:,0], csf_all_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "08286cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1818, 4)\n",
      "(1818, 3)\n"
     ]
    }
   ],
   "source": [
    "print(y_csf_ID.shape) ; print(csf_all_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0075a6",
   "metadata": {},
   "source": [
    "## Merging the outputs for 2 stage of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9cf6e513",
   "metadata": {},
   "outputs": [],
   "source": [
    "#want to find a way to inner join the ID values and the softmax values from UDS model and MRI model / other tuples \n",
    "#do a concat with NACCID and the output and then do inner join?? \n",
    "#make data frames so can do pandas inner join then will change back to array \n",
    "pred_uds_IDs_df = pd.DataFrame(uds_all_output_ID, columns = [\"NACCID\", \"UDS_C1\", \"UDS_C2\", \"UDS_C3\" ])\n",
    "pred_mri_IDs_df = pd.DataFrame(mri_all_output_ID, columns = [\"NACCID\", \"MRI_C1\", \"MRI_C2\", \"MRI_C3\"])\n",
    "pred_csf_IDs_df = pd.DataFrame(csf_all_output_ID, columns = [\"NACCID\", \"CSF_C1\", \"CSF_C2\", \"CSF_C3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9954b226",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data frames with the softmax classifiers from the first stage of models \n",
    "X_uds_mri_ID = pd.merge(pred_uds_IDs_df, pred_mri_IDs_df, on=\"NACCID\", how=\"inner\")\n",
    "X_uds_csf_ID = pd.merge(pred_uds_IDs_df, pred_csf_IDs_df, on=\"NACCID\", how=\"inner\")\n",
    "X_mri_csf_ID = pd.merge(pred_mri_IDs_df, pred_csf_IDs_df, on=\"NACCID\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a7d1c168",
   "metadata": {},
   "outputs": [],
   "source": [
    "#want to find a way to inner join the ID values and the softmax values from UDS model and MRI model / other tuples \n",
    "#do a concat with NACCID and the output and then do inner join?? \n",
    "#make data frames so can do pandas inner join then will change back to array \n",
    "y_uds_IDs_df = pd.DataFrame(y_uds_ID, columns = [\"NACCID\", \"ind_1\", \"ind_2\", \"ind_3\"])\n",
    "y_mri_IDs_df = pd.DataFrame(y_mri_ID, columns = [\"NACCID\", \"ind_1\", \"ind_2\", \"ind_3\"])\n",
    "y_csf_IDs_df = pd.DataFrame(y_csf_ID, columns = [\"NACCID\", \"ind_1\", \"ind_2\", \"ind_3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "107375dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data frames with the softmax classifiers from the first stage of models \n",
    "y_uds_mri_ID = pd.merge(y_uds_IDs_df, y_mri_IDs_df[['NACCID']], on=\"NACCID\", how=\"inner\")\n",
    "y_uds_csf_ID = pd.merge(y_uds_IDs_df, y_csf_IDs_df[['NACCID']], on=\"NACCID\", how=\"inner\")\n",
    "y_mri_csf_ID = pd.merge(y_mri_IDs_df, y_csf_IDs_df[['NACCID']], on=\"NACCID\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "5ef584c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(264, 7)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_mri_csf_ID.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47307568",
   "metadata": {},
   "source": [
    "## Stage 2 \n",
    "\n",
    "### UDS / MRI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c0be0081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2221, 7)\n",
      "(2221, 4)\n"
     ]
    }
   ],
   "source": [
    "#split data into test and train for this model\n",
    "X_uds_mri_train, X_uds_mri_test, y_uds_mri_train, y_uds_mri_test = train_test_split(X_uds_mri_ID,\n",
    "                    y_uds_mri_ID, test_size=0.05,  random_state=20)\n",
    "print(X_uds_mri_train.shape); print(y_uds_mri_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "df3cbe9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert inputs to float arrays \n",
    "X_uds_mri_train = pd.DataFrame.to_numpy(X_uds_mri_train.iloc[: , 1:]) \n",
    "X_uds_mri_train = X_uds_mri_train.astype(float)\n",
    "y_uds_mri_train = pd.DataFrame.to_numpy(y_uds_mri_train.iloc[: , 1:]) \n",
    "y_uds_mri_train = y_uds_mri_train.astype(float)\n",
    "\n",
    "#convert inputs to float arrays \n",
    "X_uds_mri_test = pd.DataFrame.to_numpy(X_uds_mri_test.iloc[: , 1:]) \n",
    "X_uds_mri_test = X_uds_mri_test.astype(float)\n",
    "y_uds_mri_test = pd.DataFrame.to_numpy(y_uds_mri_test.iloc[: , 1:]) \n",
    "y_uds_mri_test = y_uds_mri_test.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "de919f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_uds_mri = Sequential()\n",
    "model_uds_mri.add(Dense(12, activation='relu', input_dim=X_uds_mri_train.shape[1]))\n",
    "model_uds_mri.add(Dense(5, activation='relu'))\n",
    "model_uds_mri.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model_uds_mri.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy', f1_ma])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "755625ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "70/70 [==============================] - 1s 2ms/step - loss: 1.1072 - accuracy: 0.3048 - f1_score: 0.3661\n",
      "Epoch 2/10\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 0.8939 - accuracy: 0.9289 - f1_score: 0.8755\n",
      "Epoch 3/10\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 0.6745 - accuracy: 0.9392 - f1_score: 0.8833\n",
      "Epoch 4/10\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.9401 - f1_score: 0.8831\n",
      "Epoch 5/10\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 0.2774 - accuracy: 0.9406 - f1_score: 0.8859\n",
      "Epoch 6/10\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 0.2050 - accuracy: 0.9473 - f1_score: 0.9018\n",
      "Epoch 7/10\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 0.1753 - accuracy: 0.9482 - f1_score: 0.9039\n",
      "Epoch 8/10\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 0.1632 - accuracy: 0.9478 - f1_score: 0.9040\n",
      "Epoch 9/10\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 0.1572 - accuracy: 0.9464 - f1_score: 0.9025\n",
      "Epoch 10/10\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 0.1533 - accuracy: 0.9473 - f1_score: 0.9041\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e6e81115b0>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_uds_mri.fit(X_uds_mri_train, y_uds_mri_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ddcf126c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n",
      "UDS MRI Accuracy on test data: 0.9658% \n",
      " Error on test data: 0.0342 \n",
      " F1-macro on test: 0.9182\n"
     ]
    }
   ],
   "source": [
    "#pred_train_uds_mri= model_uds_mri.predict(X_uds_mri_train)\n",
    "#scores_uds_mri = model_uds_mri.evaluate(X_uds_mri_train, y_uds_mri_train, verbose=0)\n",
    "#print('uds mri Accuracy on training data: {}% \\n Error on training data: {}'.format(scores_uds_mri[1], 1 - scores_uds_mri[1]))   \n",
    " \n",
    "pred_test_uds_mri= model_uds_mri.predict(X_uds_mri_test)\n",
    "scores2_uds_mri = model_uds_mri.evaluate(X_uds_mri_test, y_uds_mri_test, verbose=0)\n",
    "print('UDS MRI Accuracy on test data: {}% \\n Error on test data: {} \\n F1-macro on test: {}'.format(round(scores2_uds_mri[1],4),\n",
    "                                                                round(1 - scores2_uds_mri[1],4), round(scores2_uds_mri[2],4))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bbfa1e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "#change all data to numpy arrays \n",
    "X_uds_mri = pd.DataFrame.to_numpy(X_uds_mri_ID.iloc[: , 1:]) \n",
    "X_uds_mri = X_uds_mri.astype(float)\n",
    "                    \n",
    "               \n",
    "#after training the network with our training test and testing set will put the whole data set into the model to give us \n",
    "#our softmax output for the next model \n",
    "uds_mri_all_output = model_uds_mri.predict(X_uds_mri)\n",
    "uds_mri_all_output_ID = np.column_stack((X_uds_mri_ID.iloc[: , 0], uds_mri_all_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f8a4329b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2338, 4)\n",
      "(2338, 4)\n"
     ]
    }
   ],
   "source": [
    "print(uds_mri_all_output_ID.shape) ; print(y_uds_mri_ID.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb484790",
   "metadata": {},
   "source": [
    "### UDS / CSF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "20263369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1727, 7)\n",
      "(1727, 4)\n"
     ]
    }
   ],
   "source": [
    "#split data into test and train for this model\n",
    "X_uds_csf_train, X_uds_csf_test, y_uds_csf_train, y_uds_csf_test = train_test_split(X_uds_csf_ID,\n",
    "                    y_uds_csf_ID, test_size=0.05,  random_state=20)\n",
    "print(X_uds_csf_train.shape); print(y_uds_csf_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "111c75e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert inputs to float arrays \n",
    "X_uds_csf_train = pd.DataFrame.to_numpy(X_uds_csf_train.iloc[: , 1:]) \n",
    "X_uds_csf_train = X_uds_csf_train.astype(float)\n",
    "y_uds_csf_train = pd.DataFrame.to_numpy(y_uds_csf_train.iloc[: , 1:]) \n",
    "y_uds_csf_train = y_uds_csf_train.astype(float)\n",
    "\n",
    "#convert inputs to float arrays \n",
    "X_uds_csf_test = pd.DataFrame.to_numpy(X_uds_csf_test.iloc[: , 1:]) \n",
    "X_uds_csf_test = X_uds_csf_test.astype(float)\n",
    "y_uds_csf_test = pd.DataFrame.to_numpy(y_uds_csf_test.iloc[: , 1:]) \n",
    "y_uds_csf_test = y_uds_csf_test.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3622906a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_uds_csf = Sequential()\n",
    "model_uds_csf.add(Dense(12, activation='relu', input_dim=X_uds_csf_train.shape[1]))\n",
    "model_uds_csf.add(Dense(6, activation='relu'))\n",
    "model_uds_csf.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model_uds_csf.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy', f1_ma])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "45842939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "54/54 [==============================] - 1s 2ms/step - loss: 1.1431 - accuracy: 0.3011 - f1_score: 0.3638\n",
      "Epoch 2/10\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.9255 - accuracy: 0.5460 - f1_score: 0.4833\n",
      "Epoch 3/10\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.8011 - accuracy: 0.9143 - f1_score: 0.6583\n",
      "Epoch 4/10\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.7050 - accuracy: 0.9195 - f1_score: 0.6742\n",
      "Epoch 5/10\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.6112 - accuracy: 0.9241 - f1_score: 0.7194\n",
      "Epoch 6/10\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.9369 - f1_score: 0.8052\n",
      "Epoch 7/10\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.3866 - accuracy: 0.9427 - f1_score: 0.8311\n",
      "Epoch 8/10\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2878 - accuracy: 0.9456 - f1_score: 0.8469\n",
      "Epoch 9/10\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.2253 - accuracy: 0.9456 - f1_score: 0.8492\n",
      "Epoch 10/10\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.1896 - accuracy: 0.9479 - f1_score: 0.8562\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e6e9528730>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_uds_csf.fit(X_uds_csf_train, y_uds_csf_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "5e84921e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 4ms/step\n",
      "UDS CSF Accuracy on test data: 0.9231% \n",
      " Error on test data: 0.0769 \n",
      " F1-macro on test: 0.8158\n"
     ]
    }
   ],
   "source": [
    "#pred_train_uds_csf= model_uds_csf.predict(X_uds_csf_train)\n",
    "#scores_uds_csf = model_uds_csf.evaluate(X_uds_csf_train, y_uds_csf_train, verbose=0)\n",
    "#print('uds csf Accuracy on training data: {}% \\n Error on training data: {}'.format(scores_uds_csf[1], 1 - scores_uds_csf[1]))   \n",
    " \n",
    "pred_test_uds_csf= model_uds_csf.predict(X_uds_csf_test)\n",
    "scores2_uds_csf = model_uds_csf.evaluate(X_uds_csf_test, y_uds_csf_test, verbose=0)\n",
    "print('UDS CSF Accuracy on test data: {}% \\n Error on test data: {} \\n F1-macro on test: {}'.format(round(scores2_uds_csf[1],4),\n",
    "                                                                        round(1 - scores2_uds_csf[1],4), round(scores2_uds_csf[2],4)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "86ed07f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "#change all data to numpy arrays \n",
    "X_uds_csf = pd.DataFrame.to_numpy(X_uds_csf_ID.iloc[: , 1:]) \n",
    "X_uds_csf = X_uds_csf.astype(float)\n",
    "                    \n",
    "               \n",
    "#after training the network with our training test and testing set will put the whole data set into the model to give us \n",
    "#our softmax output for the next model \n",
    "uds_csf_all_output = model_uds_csf.predict(X_uds_csf)\n",
    "uds_csf_all_output_ID = np.column_stack((X_uds_csf_ID.iloc[: , 0], uds_csf_all_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9e260cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1818, 4)\n",
      "(1818, 4)\n"
     ]
    }
   ],
   "source": [
    "print(uds_csf_all_output_ID.shape) ; print(y_uds_csf_ID.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3276bff6",
   "metadata": {},
   "source": [
    "### MRI / CSF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d643f018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250, 7)\n",
      "(250, 4)\n"
     ]
    }
   ],
   "source": [
    "#split data into test and train for this model\n",
    "X_mri_csf_train, X_mri_csf_test, y_mri_csf_train, y_mri_csf_test = train_test_split(X_mri_csf_ID,\n",
    "                    y_mri_csf_ID, test_size=0.05,  random_state=20)\n",
    "print(X_mri_csf_train.shape); print(y_mri_csf_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1eeaeebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert inputs to float arrays \n",
    "X_mri_csf_train = pd.DataFrame.to_numpy(X_mri_csf_train.iloc[: , 1:]) \n",
    "X_mri_csf_train = X_mri_csf_train.astype(float)\n",
    "y_mri_csf_train = pd.DataFrame.to_numpy(y_mri_csf_train.iloc[: , 1:]) \n",
    "y_mri_csf_train = y_mri_csf_train.astype(float)\n",
    "\n",
    "#convert inputs to float arrays \n",
    "X_mri_csf_test = pd.DataFrame.to_numpy(X_mri_csf_test.iloc[: , 1:]) \n",
    "X_mri_csf_test = X_mri_csf_test.astype(float)\n",
    "y_mri_csf_test = pd.DataFrame.to_numpy(y_mri_csf_test.iloc[: , 1:]) \n",
    "y_mri_csf_test = y_mri_csf_test.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "816f1671",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mri_csf = Sequential()\n",
    "model_mri_csf.add(Dense(100, activation='relu', input_dim=X_mri_csf_train.shape[1]))\n",
    "model_mri_csf.add(Dense(50, activation='relu'))\n",
    "model_mri_csf.add(Dense(20, activation='relu'))\n",
    "model_mri_csf.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model_mri_csf.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy', f1_ma])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "6b2dd81a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4363 - accuracy: 0.8400 - f1_score: 0.5654\n",
      "Epoch 2/30\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4371 - accuracy: 0.8320 - f1_score: 0.5595\n",
      "Epoch 3/30\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4346 - accuracy: 0.8360 - f1_score: 0.5635\n",
      "Epoch 4/30\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4347 - accuracy: 0.8360 - f1_score: 0.5624\n",
      "Epoch 5/30\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4343 - accuracy: 0.8400 - f1_score: 0.5665\n",
      "Epoch 6/30\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4301 - accuracy: 0.8400 - f1_score: 0.5665\n",
      "Epoch 7/30\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4322 - accuracy: 0.8360 - f1_score: 0.5635\n",
      "Epoch 8/30\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4307 - accuracy: 0.8400 - f1_score: 0.5665\n",
      "Epoch 9/30\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4310 - accuracy: 0.8400 - f1_score: 0.5654\n",
      "Epoch 10/30\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4285 - accuracy: 0.8360 - f1_score: 0.5624\n",
      "Epoch 11/30\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4280 - accuracy: 0.8360 - f1_score: 0.5624\n",
      "Epoch 12/30\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4293 - accuracy: 0.8360 - f1_score: 0.5635\n",
      "Epoch 13/30\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.8360 - f1_score: 0.5624\n",
      "Epoch 14/30\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4259 - accuracy: 0.8360 - f1_score: 0.5624\n",
      "Epoch 15/30\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4258 - accuracy: 0.8360 - f1_score: 0.5624\n",
      "Epoch 16/30\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4255 - accuracy: 0.8320 - f1_score: 0.5594\n",
      "Epoch 17/30\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4300 - accuracy: 0.8320 - f1_score: 0.5623\n",
      "Epoch 18/30\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4258 - accuracy: 0.8280 - f1_score: 0.5581\n",
      "Epoch 19/30\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4274 - accuracy: 0.8360 - f1_score: 0.5624\n",
      "Epoch 20/30\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4241 - accuracy: 0.8400 - f1_score: 0.5665\n",
      "Epoch 21/30\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4244 - accuracy: 0.8320 - f1_score: 0.5603\n",
      "Epoch 22/30\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4224 - accuracy: 0.8280 - f1_score: 0.5562\n",
      "Epoch 23/30\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4194 - accuracy: 0.8360 - f1_score: 0.5624\n",
      "Epoch 24/30\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4196 - accuracy: 0.8360 - f1_score: 0.5635\n",
      "Epoch 25/30\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4249 - accuracy: 0.8400 - f1_score: 0.6091\n",
      "Epoch 26/30\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4196 - accuracy: 0.8400 - f1_score: 0.5891\n",
      "Epoch 27/30\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4197 - accuracy: 0.8280 - f1_score: 0.5592\n",
      "Epoch 28/30\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4191 - accuracy: 0.8360 - f1_score: 0.5624\n",
      "Epoch 29/30\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4154 - accuracy: 0.8360 - f1_score: 0.5624\n",
      "Epoch 30/30\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4152 - accuracy: 0.8360 - f1_score: 0.5644\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e6f00440d0>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mri_csf.fit(X_mri_csf_train, y_mri_csf_train, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "4616d007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 79ms/step\n",
      "MRI CSF Accuracy on test data: 0.7857% \n",
      " Error on test data: 0.2143 \n",
      " F1-macro on test: 0.5359\n"
     ]
    }
   ],
   "source": [
    "#pred_train_mri_csf= model_mri_csf.predict(X_mri_csf_train)\n",
    "#scores_mri_csf = model_mri_csf.evaluate(X_mri_csf_train, y_mri_csf_train, verbose=0)\n",
    "#print('mri csf Accuracy on training data: {}% \\n Error on training data: {}'.format(scores_mri_csf[1], 1 - scores_mri_csf[1]))   \n",
    " \n",
    "pred_test_mri_csf= model_mri_csf.predict(X_mri_csf_test)\n",
    "scores2_mri_csf = model_mri_csf.evaluate(X_mri_csf_test, y_mri_csf_test, verbose=0)\n",
    "print('MRI CSF Accuracy on test data: {}% \\n Error on test data: {} \\n F1-macro on test: {}'.format(round(scores2_mri_csf[1],4),\n",
    "                                                                        round(1 - scores2_mri_csf[1],4), round(scores2_mri_csf[2],4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "6f01f18a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "#change all data to numpy arrays \n",
    "X_mri_csf = pd.DataFrame.to_numpy(X_mri_csf_ID.iloc[: , 1:]) \n",
    "X_mri_csf = X_mri_csf.astype(float)\n",
    "                    \n",
    "               \n",
    "#after training the network with our training test and testing set will put the whole data set into the model to give us \n",
    "#our softmax output for the next model \n",
    "mri_csf_all_output = model_mri_csf.predict(X_mri_csf)\n",
    "mri_csf_all_output_ID = np.column_stack((X_mri_csf_ID.iloc[: , 0], mri_csf_all_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e0538411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(264, 4)\n",
      "(264, 4)\n"
     ]
    }
   ],
   "source": [
    "print(mri_csf_all_output_ID.shape) ; print(y_mri_csf_ID.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197a5841",
   "metadata": {},
   "source": [
    "## Stage 3 - UDS/ MRI/ CSF \n",
    "\n",
    "### Input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "1f4d0f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#want to inner join all the output vectors based on the IDs \n",
    "#note that the output files are arrays and the y data is dataw frame\n",
    "#we want the input to the model to be an array (I think) so need to merge the inputs and outputs \n",
    "#then change them all to arrays \n",
    "pred_uds_mri_IDs_df = pd.DataFrame(uds_mri_all_output_ID, columns = [\"NACCID\", \"UM_1\", \"UM_C2\", \"UM_C3\"])\n",
    "pred_mri_csf_IDs_df = pd.DataFrame(mri_csf_all_output_ID, columns = [\"NACCID\", \"MC_C1\", \"MC_C2\", \"MC_C3\"])\n",
    "pred_uds_csf_IDs_df = pd.DataFrame(uds_csf_all_output_ID, columns = [\"NACCID\", \"UC_C1\", \"UC_C2\", \"UC_C3\"])\n",
    "\n",
    "#data frames with the softmax classifiers from the first stage of models \n",
    "X_UMC_ID = pd.merge(pd.merge(pred_mri_csf_IDs_df,pred_uds_csf_IDs_df,on=\"NACCID\", how=\"inner\"),pred_uds_mri_IDs_df, on=\"NACCID\", how=\"inner\")\n",
    "#X_UMC_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "14e95c2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(264, 10)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_UMC_ID.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "31cc3a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_UMC_ID = pd.merge(pd.merge(y_mri_csf_ID,y_uds_csf_ID,on=\"NACCID\", how=\"inner\"),y_uds_mri_ID, on=\"NACCID\", how=\"inner\")\n",
    "y_UMC_ID = y_UMC_ID.iloc[: , :4]\n",
    "#y_UMC_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b00ac62",
   "metadata": {},
   "source": [
    "### UDS/ MRI/ CSF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "222e5843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250, 6)\n",
      "(250, 3)\n"
     ]
    }
   ],
   "source": [
    "#split data into test and train for this model\n",
    "X_UMC_train, X_UMC_test, y_UMC_train, y_UMC_test = train_test_split(X_UMC_ID,\n",
    "                    y_UMC_ID, test_size=0.05,  random_state=20)\n",
    "print(X_mri_csf_train.shape); print(y_mri_csf_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "3de8a389",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert inputs to float arrays \n",
    "X_UMC_train = pd.DataFrame.to_numpy(X_UMC_train.iloc[: , 1:]) \n",
    "X_UMC_train = X_UMC_train.astype(float)\n",
    "y_UMC_train = pd.DataFrame.to_numpy(y_UMC_train.iloc[: , 1:]) \n",
    "y_UMC_train = y_UMC_train.astype(float)\n",
    "\n",
    "#convert inputs to float arrays \n",
    "X_UMC_test = pd.DataFrame.to_numpy(X_UMC_test.iloc[: , 1:]) \n",
    "X_UMC_test = X_UMC_test.astype(float)\n",
    "y_UMC_test = pd.DataFrame.to_numpy(y_UMC_test.iloc[: , 1:]) \n",
    "y_UMC_test = y_UMC_test.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "910dfe0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_UMC = Sequential()\n",
    "model_UMC.add(Dense(75, activation='relu', input_dim=X_UMC_train.shape[1]))\n",
    "model_UMC.add(Dense(40, activation='relu'))\n",
    "model_UMC.add(Dense(10, activation='relu'))\n",
    "model_UMC.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model_UMC.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy',f1_ma])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "5debe3d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8/8 [==============================] - 2s 6ms/step - loss: 1.0519 - accuracy: 0.5200 - f1_score: 0.5308\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.9485 - accuracy: 0.9040 - f1_score: 0.6832\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.7699 - accuracy: 0.9040 - f1_score: 0.6832\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6021 - accuracy: 0.9040 - f1_score: 0.6631\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4632 - accuracy: 0.9120 - f1_score: 0.7086\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3535 - accuracy: 0.9400 - f1_score: 0.8404\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.2777 - accuracy: 0.9480 - f1_score: 0.8678\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.2256 - accuracy: 0.9560 - f1_score: 0.8934\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1975 - accuracy: 0.9600 - f1_score: 0.9055\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.1759 - accuracy: 0.9600 - f1_score: 0.9104\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e6f1258c40>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_UMC.fit(X_UMC_train, y_UMC_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "236b2e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 150ms/step\n",
      "UDS/MRI/CSF Accuracy on test data: 1.0% \n",
      " Error on test data: 0.0 \n",
      " F1-macro on test: 1.0\n"
     ]
    }
   ],
   "source": [
    "#pred_train_UMC= model_UMC.predict(X_UMC_train)\n",
    "#scores_UMC = model_UMC.evaluate(X_UMC_train, y_UMC_train, verbose=0)\n",
    "#print('mri csf Accuracy on training data: {}% \\n Error on training data: {}'.format(scores_UMC[1], 1 - scores_UMC[1]))   \n",
    " \n",
    "pred_test_UMC= model_UMC.predict(X_UMC_test)\n",
    "scores2_UMC = model_UMC.evaluate(X_UMC_test, y_UMC_test, verbose=0)\n",
    "print('UDS/MRI/CSF Accuracy on test data: {}% \\n Error on test data: {} \\n F1-macro on test: {}'.format(round(scores2_UMC[1],4),\n",
    "                                                                        round(1 - scores2_UMC[1],4), round(scores2_UMC[2],4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ffb009",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
