{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9108310d",
   "metadata": {},
   "source": [
    "# Hierarchical Fusion\n",
    "\n",
    "This notebook implements the hierarchical fusion method introduced in https://pubmed.ncbi.nlm.nih.gov/30381863/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "936e7552",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, time\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter, defaultdict\n",
    "from importlib import reload\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "import torch\n",
    "from torch import optim, nn\n",
    "import torch.utils.data as Data\n",
    "from torch.nn import functional as F\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def seed_torch(seed=0):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)#as reproducibility docs\n",
    "    torch.manual_seed(seed)# as reproducibility docs\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False# as reproducibility docs\n",
    "    torch.backends.cudnn.deterministic = True# as reproducibility docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb903b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Distribution: Counter({'Healthy': 17673, 'Dementia-AD': 11882, 'MCI-AD': 4470})\n",
      "\n",
      "(34025, 89) (2338, 161) (1818, 7)\n"
     ]
    }
   ],
   "source": [
    "target_encoder = LabelEncoder()\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "\n",
    "def load_data(impute_method = 'Mean-Mode', target = 'NACCAD3'):\n",
    "    uds = pd.read_csv(\"../data/data_imputed/{}/uds.csv\".format(impute_method))\n",
    "    uds['datetime'] = pd.to_datetime(uds['datetime'])\n",
    "    uds = uds.dropna(subset=[target, 'EDUC'])\n",
    "    \n",
    "    print(\"Target Distribution: {}\\n\".format(Counter(uds[target])))\n",
    "    uds[target] = target_encoder.fit_transform(uds[target])\n",
    "    onehot_encoder.fit(uds[target].values.reshape(-1, 1))\n",
    "\n",
    "    mri = pd.read_csv(\"../data/data_imputed/{}/mri.csv\".format(impute_method))\n",
    "    mri['datetime'] = pd.to_datetime(mri['datetime'])\n",
    "    mri = mri[mri['NACCID'].isin(uds['NACCID'])]\n",
    "    \n",
    "    csf = pd.read_csv(\"../data/data_imputed/{}/csf.csv\".format(impute_method))\n",
    "    csf = csf[csf['NACCID'].isin(uds['NACCID'])]\n",
    "    return uds, mri, csf\n",
    "\n",
    "uds_dict = pd.read_csv(\"../data/data_dictionary/uds_feature_dictionary_cleaned.csv\")\n",
    "mri_dict = pd.read_csv(\"../data/data_dictionary/mri_feature_dictionary_cleaned.csv\") \n",
    "\n",
    "uds = uds.sort_values('NACCID')\n",
    "mri = mri.sort_values('NACCID')\n",
    "csf = csf.sort_values('NACCID')\n",
    "\n",
    "uds_drop_columns = ['NACCID', 'NACCADC', 'NACCVNUM', 'datetime', 'NACCUDSD', 'NACCALZP', 'NACCAD3', 'NACCAD5']\n",
    "mri_drop_columns = ['NACCID', 'NACCVNUM', 'datetime', 'datetime_UDS', 'timediff', 'within-a-year']\n",
    "csf_drop_columns = ['NACCID', 'CSFABMD', 'CSFTTMD', 'CSFPTMD']\n",
    "\n",
    "target = 'NACCAD3'\n",
    "uds, mri, csf = load_data(target = target)\n",
    "print(uds.shape, mri.shape, csf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cf5818",
   "metadata": {},
   "source": [
    "# Prediction Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41924ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def obtain_metrics(ytr, ytr_hat, yte, yte_hat, confusion_metrix = False, df_type=None, seed=None):\n",
    "    if confusion_metrix:\n",
    "        print(metrics.confusion_matrix(ytr, ytr_hat))\n",
    "        print(metrics.confusion_matrix(yte, yte_hat))\n",
    "        \n",
    "    acctr = metrics.accuracy_score(ytr, ytr_hat)\n",
    "    f1tr_macro = metrics.f1_score(ytr, ytr_hat, average='macro')\n",
    "    f1tr_micro = metrics.f1_score(ytr, ytr_hat, average='micro')\n",
    "    \n",
    "    accte = metrics.accuracy_score(yte, yte_hat)\n",
    "    f1te_macro = metrics.f1_score(yte, yte_hat, average='macro')\n",
    "    f1te_micro = metrics.f1_score(yte, yte_hat, average='micro')\n",
    " \n",
    "    metrics_df = pd.DataFrame.from_dict({\"Train\": {\"Acc\": acctr, \"F1-macro\": f1tr_macro, \"F1-micro\": f1tr_micro}, \n",
    "                                         \"Test\": {\"Acc\": accte, \"F1-macro\": f1te_macro, \"F1-micro\": f1te_micro}}, \n",
    "                                         orient='Index')\n",
    "    metrics_df = metrics_df.round(3)\n",
    "    if df_type is not None:\n",
    "        metrics_df['Type'] = df_type\n",
    "    if seed is not None:\n",
    "        metrics_df['Seed'] = seed\n",
    "    return metrics_df\n",
    "    \n",
    "def print_summary_clf(clf, Xtr, ytr, Xte, yte, confusion_metrix = False, df_type = None, seed=None):\n",
    "\n",
    "    metrics_df = obtain_metrics(ytr, clf.predict(Xtr), yte, clf.predict(Xte), confusion_metrix=confusion_metrix)\n",
    "    return metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d79f15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "inner_ppl = set(uds['NACCID']).intersection(mri['NACCID']).intersection(csf['NACCID'])\n",
    "inner_train_ppl, inner_test_ppl = train_test_split(np.array(list(inner_ppl)), test_size = 0.2, random_state=seed)\n",
    "outer_ppl = list(set(uds['NACCID'])- inner_ppl)\n",
    "outer_train_ppl, outer_test_ppl = train_test_split(np.array(outer_ppl), test_size = 0.2, random_state=seed)\n",
    "outer_train_ppl = np.concatenate([inner_train_ppl, outer_train_ppl])\n",
    "outer_test_ppl = np.concatenate([inner_test_ppl, outer_test_ppl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "999dcaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_index(a, b):\n",
    "    overlap_ppl = set(a['NACCID']).intersection(b['NACCID'])\n",
    "    aidx = a[a['NACCID'].isin(overlap_ppl)].reset_index().sort_values('NACCID')['index'].values\n",
    "    bidx = b[b['NACCID'].isin(overlap_ppl)].reset_index().sort_values('NACCID')['index'].values\n",
    "    return aidx, bidx\n",
    "\n",
    "def find_all_index(a, b, c):\n",
    "    overlap_ppl = set(a['NACCID']).intersection(b['NACCID']).intersection(c['NACCID'])\n",
    "    aidx = a[a['NACCID'].isin(overlap_ppl)].reset_index().sort_values('NACCID')['index'].values\n",
    "    bidx = b[b['NACCID'].isin(overlap_ppl)].reset_index().sort_values('NACCID')['index'].values\n",
    "    cidx = c[c['NACCID'].isin(overlap_ppl)].reset_index().sort_values('NACCID')['index'].values\n",
    "    return aidx, bidx, cidx\n",
    "\n",
    "atr, ate = uds[uds['NACCID'].isin(outer_train_ppl)].reset_index(drop=True), uds[uds['NACCID'].isin(outer_test_ppl)].reset_index(drop=True)\n",
    "btr, bte = mri[mri['NACCID'].isin(outer_train_ppl)].reset_index(drop=True), mri[mri['NACCID'].isin(outer_test_ppl)].reset_index(drop=True)\n",
    "ctr, cte = csf[csf['NACCID'].isin(outer_train_ppl)].reset_index(drop=True), csf[csf['NACCID'].isin(outer_test_ppl)].reset_index(drop=True)\n",
    "\n",
    "(ab_atri, ab_btri), (ab_atei, ab_btei) = find_index(atr, btr), find_index(ate, bte)\n",
    "(ac_atri, ac_ctri), (ac_atei, ac_ctei) = find_index(atr, ctr), find_index(ate, cte)\n",
    "(bc_btri, bc_ctri), (bc_btei, bc_ctei) = find_index(btr, ctr), find_index(bte, cte)\n",
    "(abc_atri, abc_btri, abc_ctri), (abc_atei, abc_btei, abc_ctei) = find_all_index(atr, btr, ctr), find_all_index(ate, bte, cte)\n",
    "abc_abtri, abc_actri = find_index(atr.loc[ab_atri].reset_index(drop=True), atr.loc[ac_atri].reset_index(drop=True))\n",
    "abc_abtri, abc_bctri = find_index(atr.loc[ab_atri].reset_index(drop=True), btr.loc[bc_btri].reset_index(drop=True))\n",
    "abc_abtei, abc_actei = find_index(ate.loc[ab_atei].reset_index(drop=True), ate.loc[ac_atei].reset_index(drop=True))\n",
    "abc_abtei, abc_bctei = find_index(ate.loc[ab_atei].reset_index(drop=True), bte.loc[bc_btei].reset_index(drop=True))\n",
    "\n",
    "# Construct Tensor\n",
    "yatr = torch.tensor(atr['NACCAD3'].to_numpy()).long().to(device)\n",
    "yate = torch.tensor(ate['NACCAD3'].to_numpy()).long().to(device)\n",
    "ybtr = torch.tensor(btr.merge(atr, on='NACCID')['NACCAD3'].to_numpy()).long().to(device)\n",
    "ybte = torch.tensor(bte.merge(ate, on='NACCID')['NACCAD3'].to_numpy()).long().to(device)\n",
    "yctr = torch.tensor(ctr.merge(atr, on='NACCID')['NACCAD3'].to_numpy()).long().to(device)\n",
    "ycte = torch.tensor(cte.merge(ate, on='NACCID')['NACCAD3'].to_numpy()).long().to(device)\n",
    "\n",
    "atr = torch.tensor(atr.drop(uds_drop_columns, axis=1).to_numpy()).float().to(device)\n",
    "ate = torch.tensor(ate.drop(uds_drop_columns, axis=1).to_numpy()).float().to(device)\n",
    "btr = torch.tensor(btr.drop(mri_drop_columns, axis=1).to_numpy()).float().to(device)\n",
    "bte = torch.tensor(bte.drop(mri_drop_columns, axis=1).to_numpy()).float().to(device)\n",
    "ctr = torch.tensor(ctr.drop(csf_drop_columns, axis=1).to_numpy()).float().to(device)\n",
    "cte = torch.tensor(cte.drop(csf_drop_columns, axis=1).to_numpy()).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e7ccb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredModel(torch.nn.Module):\n",
    "    def __init__(self, layers, seed=48):\n",
    "        super(PredModel, self).__init__()\n",
    "        seed_torch(seed)\n",
    "        linear_list = [nn.Linear(layers[0], layers[1])]\n",
    "        for i in range(2, len(layers)):\n",
    "            linear_list.append(nn.ReLU())\n",
    "            linear_list.append(nn.Dropout(0.1))\n",
    "            linear_list.append(nn.Linear(layers[i-1], layers[i]))   \n",
    "        self.layers = nn.Sequential(*linear_list)\n",
    "    def forward(self, X):\n",
    "        return self.layers(X)\n",
    "    def predict_proba(self, X):\n",
    "        return nn.Softmax()(self.layers(X)).detach().cpu().numpy()\n",
    "    def predict(self, X):\n",
    "        return nn.Softmax()(self.layers(X)).argmax(1).cpu().numpy()\n",
    "    def loss(self, X, y):\n",
    "        y_proba = self.forward(X)\n",
    "        return nn.CrossEntropyLoss()(y_proba, y)\n",
    "    \n",
    "def train_pred(clf, Xtr, ytr, Xte, yte, display_intvl=250):\n",
    "    optimizer = torch.optim.Adam(clf.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "    last_loss, loss = 0, 0\n",
    "    for epoch in range(1000):\n",
    "        loss =  clf.loss(Xtr, ytr)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (epoch % display_intvl == 0 or torch.abs(last_loss - loss) < 1e-9):\n",
    "            acc, f1_macro, f1_micro = print_summary_clf(clf, Xtr, ytr, Xte, yte).loc[\"Train\",]\n",
    "            print('Pred Epoch {}:  Loss: {:.3f}\\tAcc-{:.3f}%\\tF1_macro-{:.3f}\\tF1_micro-{:.3f}'.format(\n",
    "                epoch, loss.item(), acc*100, f1_macro, f1_micro))\n",
    "        if torch.abs(last_loss - loss) < 1e-9:\n",
    "            break\n",
    "        last_loss = loss\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c145d847",
   "metadata": {},
   "outputs": [],
   "source": [
    "aPred = PredModel([81, 32, 16, 3]).to(device)\n",
    "bPred = PredModel([155, 128, 64, 16, 3]).to(device)\n",
    "cPred = PredModel([3, 8, 4, 3]).to(device)\n",
    "abPred = PredModel([6, 4, 3]).to(device)\n",
    "acPred = PredModel([6, 4, 3]).to(device)\n",
    "bcPred = PredModel([6, 4, 3]).to(device)\n",
    "abcPred = PredModel([9, 4, 3]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a5745ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred Epoch 0:  Loss: 0.513\tAcc-79.400%\tF1_macro-0.564\tF1_micro-0.794\n",
      "Pred Epoch 250:  Loss: 0.504\tAcc-80.400%\tF1_macro-0.571\tF1_micro-0.804\n",
      "Pred Epoch 500:  Loss: 0.450\tAcc-82.000%\tF1_macro-0.591\tF1_micro-0.820\n",
      "Pred Epoch 750:  Loss: 0.571\tAcc-81.300%\tF1_macro-0.582\tF1_micro-0.813\n",
      "Pred Epoch 0:  Loss: 0.856\tAcc-67.000%\tF1_macro-0.267\tF1_micro-0.670\n",
      "Pred Epoch 250:  Loss: 0.850\tAcc-66.200%\tF1_macro-0.267\tF1_micro-0.662\n",
      "Pred Epoch 500:  Loss: 0.896\tAcc-66.700%\tF1_macro-0.267\tF1_micro-0.667\n",
      "Pred Epoch 750:  Loss: 0.898\tAcc-67.000%\tF1_macro-0.267\tF1_micro-0.670\n",
      "Pred Epoch 0:  Loss: 1.016\tAcc-37.400%\tF1_macro-0.294\tF1_micro-0.374\n",
      "Pred Epoch 250:  Loss: 0.957\tAcc-36.900%\tF1_macro-0.278\tF1_micro-0.369\n",
      "Pred Epoch 500:  Loss: 0.908\tAcc-57.000%\tF1_macro-0.261\tF1_micro-0.570\n",
      "Pred Epoch 750:  Loss: 0.879\tAcc-58.900%\tF1_macro-0.258\tF1_micro-0.589\n",
      "Pred Epoch 0:  Loss: 0.772\tAcc-76.900%\tF1_macro-0.523\tF1_micro-0.769\n",
      "Pred Epoch 250:  Loss: 0.707\tAcc-76.300%\tF1_macro-0.517\tF1_micro-0.763\n",
      "Pred Epoch 500:  Loss: 0.646\tAcc-82.300%\tF1_macro-0.569\tF1_micro-0.823\n",
      "Pred Epoch 750:  Loss: 0.587\tAcc-81.900%\tF1_macro-0.565\tF1_micro-0.819\n",
      "Pred Epoch 0:  Loss: 0.697\tAcc-79.300%\tF1_macro-0.544\tF1_micro-0.793\n",
      "Pred Epoch 250:  Loss: 0.633\tAcc-79.400%\tF1_macro-0.544\tF1_micro-0.794\n",
      "Pred Epoch 500:  Loss: 0.570\tAcc-79.100%\tF1_macro-0.543\tF1_micro-0.791\n",
      "Pred Epoch 750:  Loss: 0.524\tAcc-83.700%\tF1_macro-0.573\tF1_micro-0.837\n",
      "Pred Epoch 0:  Loss: 0.940\tAcc-60.200%\tF1_macro-0.288\tF1_micro-0.602\n",
      "Pred Epoch 250:  Loss: 0.888\tAcc-61.100%\tF1_macro-0.307\tF1_micro-0.611\n",
      "Pred Epoch 500:  Loss: 0.850\tAcc-63.500%\tF1_macro-0.259\tF1_micro-0.635\n",
      "Pred Epoch 750:  Loss: 0.837\tAcc-65.400%\tF1_macro-0.264\tF1_micro-0.654\n",
      "Pred Epoch 0:  Loss: 0.992\tAcc-45.000%\tF1_macro-0.319\tF1_micro-0.450\n",
      "Pred Epoch 250:  Loss: 0.829\tAcc-78.200%\tF1_macro-0.523\tF1_micro-0.782\n",
      "Pred Epoch 500:  Loss: 0.680\tAcc-82.900%\tF1_macro-0.566\tF1_micro-0.829\n",
      "Pred Epoch 750:  Loss: 0.579\tAcc-81.500%\tF1_macro-0.555\tF1_micro-0.815\n"
     ]
    }
   ],
   "source": [
    "aPred = train_pred(aPred, atr, yatr, ate, yate)\n",
    "bPred = train_pred(bPred, btr, ybtr, bte, ybte)\n",
    "cPred = train_pred(cPred, ctr, yctr, cte, ycte)\n",
    "\n",
    "Hatr, Hate = aPred(atr).detach(), aPred(ate).detach()\n",
    "Hbtr, Hbte = bPred(btr).detach(), bPred(bte).detach()\n",
    "Hctr, Hcte = cPred(ctr).detach(), cPred(cte).detach()\n",
    "Habtr, Habte = torch.concat([Hatr[ab_atri,], Hbtr[ab_btri,]], axis=1), torch.concat([Hate[ab_atei,], Hbte[ab_btei,]], axis=1)\n",
    "Hactr, Hacte = torch.concat([Hatr[ac_atri,], Hctr[ac_ctri,]], axis=1), torch.concat([Hate[ac_atei, ], Hcte[ac_ctei,]], axis=1)\n",
    "Hbctr, Hbcte = torch.concat([Hbtr[bc_btri,], Hctr[bc_ctri,]], axis=1), torch.concat([Hbte[bc_btei,], Hcte[bc_ctei,]], axis=1)\n",
    "abPred = train_pred(abPred, Habtr, yatr[ab_atri,], Habte, yate[ab_atei,])\n",
    "acPred = train_pred(acPred, Hactr, yatr[ac_atri,], Hacte, yate[ac_atei,])\n",
    "bcPred = train_pred(bcPred, Hbctr, ybtr[bc_btri,], Hbcte, ybte[bc_btei,])\n",
    "\n",
    "Habctr = torch.concat([abPred(Habtr.detach()).detach()[abc_abtri,], \n",
    "                       acPred(Hactr.detach()).detach()[abc_actri,], \n",
    "                       bcPred(Hbctr.detach()).detach()[abc_bctri,]], axis=1)\n",
    "Habcte = torch.concat([abPred(Habte.detach()).detach()[abc_abtei,], \n",
    "                       acPred(Hacte.detach()).detach()[abc_actei,], \n",
    "                       bcPred(Hbcte.detach()).detach()[abc_bctei,]], axis=1)\n",
    "abcPred = train_pred(abcPred, Habctr, yatr[ab_atri,][abc_abtri,], Habcte, yate[ab_atei,][abc_abtei,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f85aa7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_autoencoder_data(ppl_list, original=True):\n",
    "    U = uds[uds['NACCID'].isin(ppl_list)][['NACCID', 'NACCAD3'] + Ucol]\n",
    "    Utr = torch.tensor(U[Ucol].to_numpy()).float().to(device)\n",
    " \n",
    "    M = mri[mri['NACCID'].isin(ppl_list)][['NACCID'] + Mcol]\n",
    "    Mtr = torch.tensor(M[Mcol].to_numpy()).float().to(device)\n",
    "\n",
    "    C = csf[csf['NACCID'].isin(ppl_list)][['NACCID'] + Ccol]\n",
    "        \n",
    "    abc_ppl = np.array(list(set(U['NACCID']).intersection(M['NACCID']).intersection(C['NACCID'])))\n",
    "    ab_ppl = np.array(list(set(U['NACCID']).intersection(M['NACCID']) - set(abc_ppl)))\n",
    "    ac_ppl = np.array(list(set(U['NACCID']).intersection(C['NACCID']) - set(abc_ppl)))\n",
    "    a_ppl = np.array(list(set(U['NACCID']) - set(mri['NACCID']) - set(C['NACCID'])))\n",
    "    assert(len(abc_ppl) + len(ab_ppl) + len(ac_ppl) + len(a_ppl) == len(U))\n",
    "    \n",
    "    abc = U[U['NACCID'].isin(abc_ppl)].merge(M[M['NACCID'].isin(abc_ppl)], on='NACCID')\\\n",
    "                                  .merge(C[C['NACCID'].isin(abc_ppl)][['NACCID'] + Ccol], on='NACCID').drop(['NACCID'], axis=1)\n",
    "    ab = U[U['NACCID'].isin(ab_ppl)].merge(M[M['NACCID'].isin(ab_ppl)], on='NACCID').drop(['NACCID'], axis=1)\n",
    "    ac = U[U['NACCID'].isin(ac_ppl)].merge(C[C['NACCID'].isin(ac_ppl)][['NACCID'] + Ccol] , on='NACCID').drop(['NACCID'], axis=1)\n",
    "    a = U[U['NACCID'].isin(a_ppl)].drop(['NACCID'], axis=1)\n",
    "    y = np.concatenate([abc[target].values, ab[target].values, ac[target].values, a[target].values])\n",
    "\n",
    "    abc = torch.tensor(abc.drop(target, axis=1).to_numpy()).float().to(device)\n",
    "    ab = torch.tensor(ab.drop(target, axis=1).to_numpy()).float().to(device)\n",
    "    ac = torch.tensor(ac.drop(target, axis=1).to_numpy()).float().to(device)\n",
    "    a = torch.tensor(a.drop(target, axis=1).to_numpy()).float().to(device)\n",
    "    \n",
    "    return abc, ab, ac, a, y, Utr, Mtr\n",
    "\n",
    "Ucol, Mcol, Ccol = list(uds.drop(uds_drop_columns, axis=1).columns), \\\n",
    "               list(mri.drop(mri_drop_columns, axis=1).columns), \\\n",
    "               ['CSFABETA', 'CSFTTAU', 'CSFPTAU'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7f343cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_inner_metrics(seed=seed):\n",
    "    abc, ab, ac, a, y, Utr, Mtr = prepare_autoencoder_data(inner_train_ppl)\n",
    "    Hab = torch.concat([aPred(abc[:,:len(Ucol)]), bPred(abc[:,len(Ucol):len(Ucol)+len(Mcol)])], axis=1)\n",
    "    Hac = torch.concat([aPred(abc[:,:len(Ucol)]), cPred(abc[:,len(Ucol)+len(Mcol):])], axis=1)\n",
    "    Hbc = torch.concat([bPred(abc[:,len(Ucol):len(Ucol)+len(Mcol)]), cPred(abc[:,len(Ucol)+len(Mcol):])], axis=1)\n",
    "    ytr = y\n",
    "    ytr_hat = abcPred.predict(torch.concat([abPred(Hab), acPred(Hac), bcPred(Hbc)], axis=1))\n",
    "\n",
    "    abc, ab, ac, a, y, Utr, Mtr = prepare_autoencoder_data(inner_test_ppl)\n",
    "    Hab = torch.concat([aPred(abc[:,:len(Ucol)]), bPred(abc[:,len(Ucol):len(Ucol)+len(Mcol)])], axis=1)\n",
    "    Hac = torch.concat([aPred(abc[:,:len(Ucol)]), cPred(abc[:,len(Ucol)+len(Mcol):])], axis=1)\n",
    "    Hbc = torch.concat([bPred(abc[:,len(Ucol):len(Ucol)+len(Mcol)]), cPred(abc[:,len(Ucol)+len(Mcol):])], axis=1)\n",
    "    yte = y\n",
    "    yte_hat = abcPred.predict(torch.concat([abPred(Hab), acPred(Hac), bcPred(Hbc)], axis=1))\n",
    "    return obtain_metrics(ytr, ytr_hat, yte, yte_hat, df_type='Hierachical', seed=seed)\n",
    "\n",
    "def obtain_outer_metrics(seed=seed):\n",
    "    abc, ab, ac, a, y, Utr, Mtr = prepare_autoencoder_data(outer_train_ppl)\n",
    "    Hab = torch.concat([aPred(abc[:,:len(Ucol)]), bPred(abc[:,len(Ucol):len(Ucol)+len(Mcol)])], axis=1)\n",
    "    Hac = torch.concat([aPred(abc[:,:len(Ucol)]), cPred(abc[:,len(Ucol)+len(Mcol):])], axis=1)\n",
    "    Hbc = torch.concat([bPred(abc[:,len(Ucol):len(Ucol)+len(Mcol)]), cPred(abc[:,len(Ucol)+len(Mcol):])], axis=1)\n",
    "    yabc = abcPred.predict(torch.concat([abPred(Hab), acPred(Hac), bcPred(Hbc)], axis=1))\n",
    "\n",
    "    Hab = torch.concat([aPred(ab[:,:len(Ucol)]), bPred(ab[:,len(Ucol):])], axis=1)\n",
    "    yab = abPred.predict(Hab)\n",
    "\n",
    "    Hac = torch.concat([aPred(ac[:,:len(Ucol)]), cPred(ac[:,len(Ucol):])], axis=1)\n",
    "    yac = acPred.predict(Hac)\n",
    "\n",
    "    ya = aPred.predict(a)\n",
    "    \n",
    "    ytr = y\n",
    "    ytr_hat = np.concatenate([yabc, yab, yac, ya], axis=0)\n",
    "    \n",
    "    abc, ab, ac, a, y, Utr, Mtr = prepare_autoencoder_data(outer_test_ppl)\n",
    "    Hab = torch.concat([aPred(abc[:,:len(Ucol)]), bPred(abc[:,len(Ucol):len(Ucol)+len(Mcol)])], axis=1)\n",
    "    Hac = torch.concat([aPred(abc[:,:len(Ucol)]), cPred(abc[:,len(Ucol)+len(Mcol):])], axis=1)\n",
    "    Hbc = torch.concat([bPred(abc[:,len(Ucol):len(Ucol)+len(Mcol)]), cPred(abc[:,len(Ucol)+len(Mcol):])], axis=1)\n",
    "    yabc = abcPred.predict(torch.concat([abPred(Hab), acPred(Hac), bcPred(Hbc)], axis=1))\n",
    "\n",
    "    Hab = torch.concat([aPred(ab[:,:len(Ucol)]), bPred(ab[:,len(Ucol):])], axis=1)\n",
    "    yab = abPred.predict(Hab)\n",
    "\n",
    "    Hac = torch.concat([aPred(ac[:,:len(Ucol)]), cPred(ac[:,len(Ucol):])], axis=1)\n",
    "    yac = acPred.predict(Hac)\n",
    "\n",
    "    ya = aPred.predict(a)\n",
    "\n",
    "    yte = y\n",
    "    yte_hat = np.concatenate([yabc, yab, yac, ya], axis=0)\n",
    "    return obtain_metrics(ytr, ytr_hat, yte, yte_hat, df_type='Hierachical', seed=seed)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bfc2900d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acc</th>\n",
       "      <th>F1-macro</th>\n",
       "      <th>F1-micro</th>\n",
       "      <th>Type</th>\n",
       "      <th>Seed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Train</th>\n",
       "      <td>0.791</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.791</td>\n",
       "      <td>Hierachical</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test</th>\n",
       "      <td>0.774</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.774</td>\n",
       "      <td>Hierachical</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Acc  F1-macro  F1-micro         Type  Seed\n",
       "Train  0.791     0.519     0.791  Hierachical     1\n",
       "Test   0.774     0.485     0.774  Hierachical     1"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obtain_inner_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d4abd98c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acc</th>\n",
       "      <th>F1-macro</th>\n",
       "      <th>F1-micro</th>\n",
       "      <th>Type</th>\n",
       "      <th>Seed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Train</th>\n",
       "      <td>0.830</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.830</td>\n",
       "      <td>Hierachical</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test</th>\n",
       "      <td>0.825</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.825</td>\n",
       "      <td>Hierachical</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Acc  F1-macro  F1-micro         Type  Seed\n",
       "Train  0.830     0.592     0.830  Hierachical     1\n",
       "Test   0.825     0.591     0.825  Hierachical     1"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obtain_outer_metrics()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
